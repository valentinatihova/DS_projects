{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Работа получилась отличной, тебе удалось добиться достаточно хорошего качества. Поздравляю!\n",
    "* Проект может быть зачтен, но я его отправлю назад, чтобы у тебя была возможность задать вопросы и внести правки, при желании. Однако, ты можешь просто вернуть проект в таком же виде и я его зачту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> Привет! Большое спасибо за проверку моей работы! И отдельное спасибо за дополнительные материалы, мне их не хватало в теоретической части. Обязательно их посмотрю, возможно чем-то новым дополню свою работу. В частности локально попробую поработать с BERT и другими методами работы с текстами.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* Проект зачтен!\n",
    "* Удачи в дальнейшем обучении и следующих работах!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим необходимые библиотеки и дата-сет и выведем несколько строк для наглядности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from tqdm import notebook\n",
    "# from wordcloud import STOPWORDS, ImageColorGenerator, WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Желательно чтобы все импорты были собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>tmbox|type=notice|text=Please note: I am not a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19147</th>\n",
       "      <td>, 18 April 2009 (UTC)'''   21:48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49480</th>\n",
       "      <td>hi - i'm sorry, i'm struggling to get my refer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19732</th>\n",
       "      <td>Eliminated that sentence.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140447</th>\n",
       "      <td>\"\\nUnits that are unique, like the East Asia S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "4654    tmbox|type=notice|text=Please note: I am not a...      0\n",
       "19147                    , 18 April 2009 (UTC)'''   21:48      0\n",
       "49480   hi - i'm sorry, i'm struggling to get my refer...      0\n",
       "19732                           Eliminated that sentence.      0\n",
       "140447  \"\\nUnits that are unique, like the East Asia S...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', usecols = ['text', 'toxic'])\n",
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл содержит 159k записей и две колонки: текст комментария `text` и целевой признак `toxic`. Пропусков в данных нет. Посмотрим на соотношение класса целевого признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение объектов класса 1 к общей выборке: 10.16%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Соотношение объектов класса 1 к общей выборке: {sum(df.toxic)*100/df.shape[0]:.2f}%')\n",
    "sns.countplot(x = 'toxic', data = df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find 0 duplicate in a DataFrame\n"
     ]
    }
   ],
   "source": [
    "print(f'Find {df.duplicated().sum()} duplicate in a DataFrame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем обработку текста с помощью вспомогательных функций:\n",
    "- подготовка данных `preprocess_text` для удаления тегов, символов пунктуации, цифр, одиночных символов и двойных пробелов\n",
    "- токенизация текста `tokenization`, то есть разделим слова на составляющие\n",
    "- уберем стоп-слова `remove_stopwords`\n",
    "- стемминг текста `stemming`, то есть нарезка некоторых общих префиксов или суффиксов в начале или конце слова\n",
    "- лемматизация `lemmatizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно. Радует, что баланс классов был изучен.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(txt):\n",
    "    # удалим тэги\n",
    "    text = ''\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    text = TAG_RE.sub('', txt)\n",
    "\n",
    "    # удалим пунктуацию и цифры\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # удалим одиночные символы\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "\n",
    "    # удалим двойные пробелы\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenization(txt):\n",
    "    txt = re.split('\\W+', txt)\n",
    "    return txt\n",
    "\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    txt = [word for word in txt if word not in stopword]\n",
    "    return txt\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(txt):\n",
    "    txt = [wn.lemmatize(word) for word in txt]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим все написанные функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>preprocess_text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56407</th>\n",
       "      <td>UTC+8 \\n\\nSingapore. – acor</td>\n",
       "      <td>0</td>\n",
       "      <td>UTC Singapore acor</td>\n",
       "      <td>[utc, singapore, acor]</td>\n",
       "      <td>[utc, singapore, acor]</td>\n",
       "      <td>[utc, singapore, acor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52335</th>\n",
       "      <td>February 2011 (UTC)\\nWe don't have an undisput...</td>\n",
       "      <td>0</td>\n",
       "      <td>February UTC We don have an undisputed source ...</td>\n",
       "      <td>[february, utc, we, don, have, an, undisputed,...</td>\n",
       "      <td>[february, utc, undisputed, source, syria, rec...</td>\n",
       "      <td>[february, utc, undisputed, source, syria, rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41525</th>\n",
       "      <td>\"\\n\\n Re: Discussions on fair use \\nI wish I c...</td>\n",
       "      <td>0</td>\n",
       "      <td>Re Discussions on fair use wish could point y...</td>\n",
       "      <td>[, re, discussions, on, fair, use, wish, could...</td>\n",
       "      <td>[, discussions, fair, use, wish, could, point,...</td>\n",
       "      <td>[, discussion, fair, use, wish, could, point, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81458</th>\n",
       "      <td>\"IP 65.35.248.179 Dislikes Scienceman123 (ALOT...</td>\n",
       "      <td>1</td>\n",
       "      <td>IP Dislikes Scienceman ALOT See topic and dis...</td>\n",
       "      <td>[, ip, dislikes, scienceman, alot, see, topic,...</td>\n",
       "      <td>[, ip, dislikes, scienceman, alot, see, topic,...</td>\n",
       "      <td>[, ip, dislike, scienceman, alot, see, topic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147069</th>\n",
       "      <td>blank PH map \\n\\nCan you provide me a blank PH...</td>\n",
       "      <td>0</td>\n",
       "      <td>blank PH map Can you provide me blank PH map t...</td>\n",
       "      <td>[blank, ph, map, can, you, provide, me, blank,...</td>\n",
       "      <td>[blank, ph, map, provide, blank, ph, map, use,...</td>\n",
       "      <td>[blank, ph, map, provide, blank, ph, map, use,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "56407                         UTC+8 \\n\\nSingapore. – acor      0   \n",
       "52335   February 2011 (UTC)\\nWe don't have an undisput...      0   \n",
       "41525   \"\\n\\n Re: Discussions on fair use \\nI wish I c...      0   \n",
       "81458   \"IP 65.35.248.179 Dislikes Scienceman123 (ALOT...      1   \n",
       "147069  blank PH map \\n\\nCan you provide me a blank PH...      0   \n",
       "\n",
       "                                          preprocess_text  \\\n",
       "56407                                  UTC Singapore acor   \n",
       "52335   February UTC We don have an undisputed source ...   \n",
       "41525    Re Discussions on fair use wish could point y...   \n",
       "81458    IP Dislikes Scienceman ALOT See topic and dis...   \n",
       "147069  blank PH map Can you provide me blank PH map t...   \n",
       "\n",
       "                                                tokenized  \\\n",
       "56407                              [utc, singapore, acor]   \n",
       "52335   [february, utc, we, don, have, an, undisputed,...   \n",
       "41525   [, re, discussions, on, fair, use, wish, could...   \n",
       "81458   [, ip, dislikes, scienceman, alot, see, topic,...   \n",
       "147069  [blank, ph, map, can, you, provide, me, blank,...   \n",
       "\n",
       "                                                  nonstop  \\\n",
       "56407                              [utc, singapore, acor]   \n",
       "52335   [february, utc, undisputed, source, syria, rec...   \n",
       "41525   [, discussions, fair, use, wish, could, point,...   \n",
       "81458   [, ip, dislikes, scienceman, alot, see, topic,...   \n",
       "147069  [blank, ph, map, provide, blank, ph, map, use,...   \n",
       "\n",
       "                                               lemmatized  \n",
       "56407                              [utc, singapore, acor]  \n",
       "52335   [february, utc, undisputed, source, syria, rec...  \n",
       "41525   [, discussion, fair, use, wish, could, point, ...  \n",
       "81458   [, ip, dislike, scienceman, alot, see, topic, ...  \n",
       "147069  [blank, ph, map, provide, blank, ph, map, use,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['preprocess_text'] = df['text'].apply(lambda x: preprocess_text(x))\n",
    "df['tokenized'] = df['preprocess_text'].apply(lambda x: tokenization(x.lower()))\n",
    "df['nonstop'] = df['tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "df['lemmatized'] = df['nonstop'].apply(lambda x: lemmatizer(x))\n",
    "\n",
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны верно, молодец!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим сет на тренировочную и тестовую выборки в отношении 70:30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.lemmatized\n",
    "y = df.toxic.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного корпуса: 111504\n",
      "Размер тренировочного корпуса: 47788\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размер тренировочного корпуса: {len(X_train)}\")\n",
    "print(f\"Размер тренировочного корпуса: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем векторизацию корпусов с помощью `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(X_train.apply(lambda x: ' '.join(x)))\n",
    "X_test_bow = vectorizer.fit_transform(X_test.apply(lambda x: ' '.join(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочного датасета: (111504, 5000)\n",
      "Размер тестового датасета: (47788, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размер тренировочного датасета: {X_train_bow.shape}\")\n",
    "print(f\"Размер тестового датасета: {X_test_bow.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано верно. Отлично, что векторизатор был обучен только на тренировочной части данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем константную модель и метрику accuracy для нее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy константной модели 0.899\n"
     ]
    }
   ],
   "source": [
    "base_predicts = pd.Series(data=np.zeros((len(y_test))), index=y_test, dtype='int16')\n",
    "base_accuacy = accuracy_score(y_test, base_predicts)\n",
    "print(f\"Accuracy константной модели {base_accuacy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель логичтической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
      "[CV] END ..............................C=10.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=10.0, max_iter=1000; total time=   2.1s\n",
      "[CV] END ..............................C=10.0, max_iter=1000; total time=   2.7s\n",
      "[CV] END ..............................C=10.0, max_iter=1000; total time=   2.4s\n",
      "[CV] END ..............................C=10.0, max_iter=1000; total time=   1.9s\n",
      "[CV] END ..............................C=11.0, max_iter=1000; total time=   2.2s\n",
      "[CV] END ..............................C=11.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=11.0, max_iter=1000; total time=   2.8s\n",
      "[CV] END ..............................C=11.0, max_iter=1000; total time=   2.7s\n",
      "[CV] END ..............................C=11.0, max_iter=1000; total time=   2.4s\n",
      "[CV] END ..............................C=12.0, max_iter=1000; total time=   2.4s\n",
      "[CV] END ..............................C=12.0, max_iter=1000; total time=   2.4s\n",
      "[CV] END ..............................C=12.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=12.0, max_iter=1000; total time=   2.2s\n",
      "[CV] END ..............................C=12.0, max_iter=1000; total time=   2.2s\n",
      "[CV] END ..............................C=13.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=13.0, max_iter=1000; total time=   2.3s\n",
      "[CV] END ..............................C=13.0, max_iter=1000; total time=   3.3s\n",
      "[CV] END ..............................C=13.0, max_iter=1000; total time=   2.7s\n",
      "[CV] END ..............................C=13.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=14.0, max_iter=1000; total time=   2.9s\n",
      "[CV] END ..............................C=14.0, max_iter=1000; total time=   2.0s\n",
      "[CV] END ..............................C=14.0, max_iter=1000; total time=   3.0s\n",
      "[CV] END ..............................C=14.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=14.0, max_iter=1000; total time=   2.7s\n",
      "[CV] END ..............................C=15.0, max_iter=1000; total time=   1.9s\n",
      "[CV] END ..............................C=15.0, max_iter=1000; total time=   3.0s\n",
      "[CV] END ..............................C=15.0, max_iter=1000; total time=   3.1s\n",
      "[CV] END ..............................C=15.0, max_iter=1000; total time=   2.1s\n",
      "[CV] END ..............................C=15.0, max_iter=1000; total time=   2.9s\n",
      "[CV] END ..............................C=16.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=16.0, max_iter=1000; total time=   2.3s\n",
      "[CV] END ..............................C=16.0, max_iter=1000; total time=   2.2s\n",
      "[CV] END ..............................C=16.0, max_iter=1000; total time=   2.7s\n",
      "[CV] END ..............................C=16.0, max_iter=1000; total time=   2.9s\n",
      "[CV] END ..............................C=17.0, max_iter=1000; total time=   2.8s\n",
      "[CV] END ..............................C=17.0, max_iter=1000; total time=   3.0s\n",
      "[CV] END ..............................C=17.0, max_iter=1000; total time=   2.9s\n",
      "[CV] END ..............................C=17.0, max_iter=1000; total time=   2.0s\n",
      "[CV] END ..............................C=17.0, max_iter=1000; total time=   1.9s\n",
      "[CV] END ..............................C=18.0, max_iter=1000; total time=   2.8s\n",
      "[CV] END ..............................C=18.0, max_iter=1000; total time=   2.5s\n",
      "[CV] END ..............................C=18.0, max_iter=1000; total time=   2.4s\n",
      "[CV] END ..............................C=18.0, max_iter=1000; total time=   3.4s\n",
      "[CV] END ..............................C=18.0, max_iter=1000; total time=   2.8s\n",
      "[CV] END ..............................C=19.0, max_iter=1000; total time=   3.7s\n",
      "[CV] END ..............................C=19.0, max_iter=1000; total time=   2.6s\n",
      "[CV] END ..............................C=19.0, max_iter=1000; total time=   3.4s\n",
      "[CV] END ..............................C=19.0, max_iter=1000; total time=   3.0s\n",
      "[CV] END ..............................C=19.0, max_iter=1000; total time=   2.9s\n",
      "[CV] END ..............................C=20.0, max_iter=1000; total time=   2.4s\n",
      "[CV] END ..............................C=20.0, max_iter=1000; total time=   3.4s\n",
      "[CV] END ..............................C=20.0, max_iter=1000; total time=   2.7s\n",
      "[CV] END ..............................C=20.0, max_iter=1000; total time=   2.5s\n",
      "[CV] END ..............................C=20.0, max_iter=1000; total time=   2.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20.]),\n",
       "                         'max_iter': [1000]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': np.linspace(10, 20, num = 11, endpoint = True),\n",
    "             'max_iter': [1000]}\n",
    "lrm = LogisticRegression()\n",
    "clf = GridSearchCV(lrm,\n",
    "                   parameters,\n",
    "                  cv=5,\n",
    "                  scoring='f1',\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "clf.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший показатель f1 на кросс-валидации : 0.771\n",
      "Параметр регуляризации для лучшей модели: {'C': 10.0, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Наилучший показатель f1 на кросс-валидации : {clf.best_score_:.3f}\")\n",
    "print(f\"Параметр регуляризации для лучшей модели: {clf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LogisticRegression(C=13, max_iter=1000)\n",
    "lrm.fit(X_train_bow, y_train)\n",
    "predict = lrm.predict(X_test_bow)\n",
    "f1_lr = f1_score(y_test, predict)\n",
    "accuracy_lr = accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатель f1 на тестовой выборке: 0.148\n",
      "Accuracy 0.882\n"
     ]
    }
   ],
   "source": [
    "print(f\"Показатель f1 на тестовой выборке: {f1_lr:.3f}\")\n",
    "print(f\"Accuracy {accuracy_lr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель LinearSVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "[CV] END ..............................................C=1.0; total time=   0.6s\n",
      "[CV] END ..............................................C=1.0; total time=   0.6s\n",
      "[CV] END ..............................................C=1.0; total time=   0.6s\n",
      "[CV] END ..............................................C=1.0; total time=   0.6s\n",
      "[CV] END ..............................................C=1.0; total time=   0.6s\n",
      "[CV] END ..............................................C=6.0; total time=   1.9s\n",
      "[CV] END ..............................................C=6.0; total time=   1.6s\n",
      "[CV] END ..............................................C=6.0; total time=   1.6s\n",
      "[CV] END ..............................................C=6.0; total time=   1.5s\n",
      "[CV] END ..............................................C=6.0; total time=   1.8s\n",
      "[CV] END .............................................C=11.0; total time=   3.1s\n",
      "[CV] END .............................................C=11.0; total time=   2.3s\n",
      "[CV] END .............................................C=11.0; total time=   3.1s\n",
      "[CV] END .............................................C=11.0; total time=   2.3s\n",
      "[CV] END .............................................C=11.0; total time=   2.4s\n",
      "[CV] END .............................................C=16.0; total time=   4.1s\n",
      "[CV] END .............................................C=16.0; total time=   4.2s\n",
      "[CV] END .............................................C=16.0; total time=   3.2s\n",
      "[CV] END .............................................C=16.0; total time=   4.3s\n",
      "[CV] END .............................................C=16.0; total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=21.0; total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=21.0; total time=   4.4s\n",
      "[CV] END .............................................C=21.0; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=21.0; total time=   4.5s\n",
      "[CV] END .............................................C=21.0; total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=26.0; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=26.0; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=26.0; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=26.0; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=26.0; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=31.0; total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=31.0; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=31.0; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=31.0; total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .............................................C=31.0; total time=   5.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(), n_jobs=-1,\n",
       "             param_grid={'C': array([ 1.,  6., 11., 16., 21., 26., 31.])},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': np.linspace(1, 31, num = 7, endpoint = True)}\n",
    "lsvcm = LinearSVC(max_iter = 1000)\n",
    "clf_lsvc = GridSearchCV(lsvcm,\n",
    "                        parameters,\n",
    "                  cv=5,\n",
    "                  scoring='f1',\n",
    "                  n_jobs=-1,\n",
    "                  verbose=2)\n",
    "\n",
    "clf_lsvc.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучший показатель f1 на кросс-валидации : 0.772\n",
      "Параметр регуляризации для лучшей модели: {'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Наилучший показатель f1 на кросс-валидации : {clf_lsvc.best_score_:.3f}\")\n",
    "print(f\"Параметр регуляризации для лучшей модели: {clf_lsvc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LinearSVC(C=13, max_iter=1000)\n",
    "lrm.fit(X_train_bow, y_train)\n",
    "predict = lrm.predict(X_test_bow)\n",
    "f1_lr = f1_score(y_test, predict)\n",
    "accuracy_lr = accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Показатель f1 на тестовой выборке: 0.150\n",
      "Accuracy 0.878\n"
     ]
    }
   ],
   "source": [
    "print(f\"Показатель f1 на тестовой выборке: {f1_lr:.3f}\")\n",
    "print(f\"Accuracy {accuracy_lr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что попробовал разные модели в этом шаге!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загруженные данные твитов успешно очищенных:\n",
    "- проведена лемматизация\n",
    "- удалены лишние символы и стоп-слова\n",
    "- проведена токетизация\n",
    "- векторизован корпус\n",
    "- обучены модели и метрика f1-score почти не отличаются друг от друга\n",
    "- проведена кросс-валидация модели и выбраны гиперпараметры\n",
    "- сделана проверка на адекватность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть вывод в конце проекта!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1307,
    "start_time": "2022-10-14T13:08:31.957Z"
   },
   {
    "duration": 3173,
    "start_time": "2022-10-14T13:08:51.833Z"
   },
   {
    "duration": 882,
    "start_time": "2022-10-14T13:17:57.970Z"
   },
   {
    "duration": 14,
    "start_time": "2022-10-14T13:18:45.405Z"
   },
   {
    "duration": 255,
    "start_time": "2022-10-14T13:18:50.845Z"
   },
   {
    "duration": 30,
    "start_time": "2022-10-14T13:19:20.308Z"
   },
   {
    "duration": 208,
    "start_time": "2022-10-14T13:19:45.188Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-14T13:19:52.701Z"
   },
   {
    "duration": 55,
    "start_time": "2022-10-14T13:20:22.836Z"
   },
   {
    "duration": 278,
    "start_time": "2022-10-14T13:20:57.791Z"
   },
   {
    "duration": 1258,
    "start_time": "2022-10-14T13:28:53.475Z"
   },
   {
    "duration": 3317,
    "start_time": "2022-10-14T13:28:54.735Z"
   },
   {
    "duration": 33,
    "start_time": "2022-10-14T13:28:58.054Z"
   },
   {
    "duration": 15,
    "start_time": "2022-10-14T13:28:58.089Z"
   },
   {
    "duration": 290,
    "start_time": "2022-10-14T13:28:58.106Z"
   },
   {
    "duration": 6,
    "start_time": "2022-10-14T13:28:58.398Z"
   },
   {
    "duration": 108,
    "start_time": "2022-10-14T13:29:38.419Z"
   },
   {
    "duration": 12,
    "start_time": "2022-10-14T13:29:50.344Z"
   },
   {
    "duration": 9218,
    "start_time": "2022-10-14T13:30:15.585Z"
   },
   {
    "duration": 28140,
    "start_time": "2022-10-14T13:32:27.692Z"
   },
   {
    "duration": 9254,
    "start_time": "2022-10-14T13:33:27.685Z"
   },
   {
    "duration": 47631,
    "start_time": "2022-10-14T13:33:44.966Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-14T13:34:59.996Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-14T13:36:20.781Z"
   },
   {
    "duration": 1159,
    "start_time": "2022-10-14T13:36:27.853Z"
   },
   {
    "duration": 878,
    "start_time": "2022-10-14T13:36:29.014Z"
   },
   {
    "duration": 32,
    "start_time": "2022-10-14T13:36:29.893Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-14T13:36:29.927Z"
   },
   {
    "duration": 243,
    "start_time": "2022-10-14T13:36:29.944Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-14T13:36:30.188Z"
   },
   {
    "duration": 127,
    "start_time": "2022-10-14T13:36:30.198Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-14T13:36:30.326Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-14T13:37:01.540Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-14T13:37:02.727Z"
   },
   {
    "duration": 8,
    "start_time": "2022-10-14T13:37:05.859Z"
   },
   {
    "duration": 1232,
    "start_time": "2022-10-14T13:37:12.882Z"
   },
   {
    "duration": 909,
    "start_time": "2022-10-14T13:37:14.116Z"
   },
   {
    "duration": 31,
    "start_time": "2022-10-14T13:37:15.027Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-14T13:37:15.060Z"
   },
   {
    "duration": 239,
    "start_time": "2022-10-14T13:37:15.074Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-14T13:37:15.314Z"
   },
   {
    "duration": 112,
    "start_time": "2022-10-14T13:37:15.319Z"
   },
   {
    "duration": 0,
    "start_time": "2022-10-14T13:37:15.432Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-14T13:37:21.153Z"
   },
   {
    "duration": 114,
    "start_time": "2022-10-14T13:37:26.760Z"
   },
   {
    "duration": 28,
    "start_time": "2022-10-14T13:37:51.787Z"
   },
   {
    "duration": 1145,
    "start_time": "2022-10-14T13:39:41.261Z"
   },
   {
    "duration": 852,
    "start_time": "2022-10-14T13:39:42.408Z"
   },
   {
    "duration": 35,
    "start_time": "2022-10-14T13:39:43.261Z"
   },
   {
    "duration": 13,
    "start_time": "2022-10-14T13:39:43.298Z"
   },
   {
    "duration": 223,
    "start_time": "2022-10-14T13:39:43.312Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-14T13:39:43.536Z"
   },
   {
    "duration": 1258,
    "start_time": "2022-10-14T13:41:45.053Z"
   },
   {
    "duration": 876,
    "start_time": "2022-10-14T13:41:46.313Z"
   },
   {
    "duration": 36,
    "start_time": "2022-10-14T13:41:47.191Z"
   },
   {
    "duration": 152,
    "start_time": "2022-10-14T13:41:47.229Z"
   },
   {
    "duration": 242,
    "start_time": "2022-10-14T13:41:47.384Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-14T13:41:47.628Z"
   },
   {
    "duration": 1241,
    "start_time": "2022-10-14T13:42:47.983Z"
   },
   {
    "duration": 866,
    "start_time": "2022-10-14T13:42:49.226Z"
   },
   {
    "duration": 32,
    "start_time": "2022-10-14T13:42:50.093Z"
   },
   {
    "duration": 145,
    "start_time": "2022-10-14T13:42:50.127Z"
   },
   {
    "duration": 236,
    "start_time": "2022-10-14T13:42:50.273Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-14T13:42:50.511Z"
   },
   {
    "duration": 1119,
    "start_time": "2022-10-14T13:43:38.207Z"
   },
   {
    "duration": 869,
    "start_time": "2022-10-14T13:43:39.328Z"
   },
   {
    "duration": 31,
    "start_time": "2022-10-14T13:43:40.199Z"
   },
   {
    "duration": 137,
    "start_time": "2022-10-14T13:43:40.232Z"
   },
   {
    "duration": 231,
    "start_time": "2022-10-14T13:43:40.370Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-14T13:43:40.603Z"
   },
   {
    "duration": 11,
    "start_time": "2022-10-14T13:43:40.608Z"
   },
   {
    "duration": 1392,
    "start_time": "2022-10-16T11:51:36.851Z"
   },
   {
    "duration": 3794,
    "start_time": "2022-10-17T06:33:22.779Z"
   },
   {
    "duration": 5,
    "start_time": "2022-10-17T06:33:37.833Z"
   },
   {
    "duration": 3004,
    "start_time": "2022-10-17T06:33:50.889Z"
   },
   {
    "duration": 30,
    "start_time": "2022-10-17T06:33:56.600Z"
   },
   {
    "duration": 109,
    "start_time": "2022-10-17T06:34:02.883Z"
   },
   {
    "duration": 206,
    "start_time": "2022-10-17T06:34:05.560Z"
   },
   {
    "duration": 280,
    "start_time": "2022-10-17T06:34:35.403Z"
   },
   {
    "duration": 43386,
    "start_time": "2022-10-17T06:35:07.376Z"
   },
   {
    "duration": 36,
    "start_time": "2022-10-17T06:36:37.757Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-17T06:36:45.761Z"
   },
   {
    "duration": 4328,
    "start_time": "2022-10-17T06:38:21.463Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-17T06:38:29.375Z"
   },
   {
    "duration": 9,
    "start_time": "2022-10-17T06:38:51.284Z"
   },
   {
    "duration": 146601,
    "start_time": "2022-10-17T06:39:18.383Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-17T06:43:02.520Z"
   },
   {
    "duration": 3283,
    "start_time": "2022-10-17T06:43:05.322Z"
   },
   {
    "duration": 4,
    "start_time": "2022-10-17T06:43:09.492Z"
   },
   {
    "duration": 115337,
    "start_time": "2022-10-17T06:43:13.346Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-17T06:45:08.685Z"
   },
   {
    "duration": 5270,
    "start_time": "2022-10-17T06:45:08.690Z"
   },
   {
    "duration": 3,
    "start_time": "2022-10-17T06:45:13.961Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
